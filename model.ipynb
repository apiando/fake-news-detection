{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb1373",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827af034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f97fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df = pd.read_csv(\"True.csv\")\n",
    "fake_df = pd.read_csv(\"Fake.csv\")\n",
    "\n",
    "true_df[\"label\"] = 1\n",
    "fake_df[\"label\"] = 0\n",
    "\n",
    "df = pd.concat([true_df, fake_df], axis=0)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df = df[[\"title\", \"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3151af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.sample(1000)  # Sample 1000 rows from df\n",
    "data = data.drop(columns=[\"text\"])  # Drop the 'text' column from the sampled data\n",
    "data.sample(10)  # Display a random sample of 10 rows from data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7630cb15",
   "metadata": {},
   "source": [
    "Load and Label Data:\n",
    "- We are loading both real and fake news datasets\n",
    "- Adds a label column: 1 for true, 0 for fake\n",
    "- Combines and shuffles the dataset\n",
    "- Extracts the news the title and labels as Python lists\n",
    "- Splits into training and validation sets in this case we are doing 80 training/20 validation split (line 18). Giving 80% ensures the model sees diverse examples and 20% prevents overfitting (preventing that when model memorizes but fails in real. 50/50 too little 90/10 not reliable for small datas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fcf62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2)\n",
    "train_df = pd.DataFrame({\"text\": train_texts, \"label\": train_labels})\n",
    "val_df = pd.DataFrame({\"text\": val_texts, \"label\": val_labels})\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1382ea35",
   "metadata": {},
   "source": [
    "Tokenization\n",
    "- We are loading BERT tokenizer that converts raw text into input IDs and attention masks so that BERT can understand. This is a pretrained BERT tokenizer.\n",
    "- Adds padding and truncates to 512 tokens max (BERT's limit).\n",
    "- Wraps the inputs and labels into datatsets that Trainer can understand. All fields must be lists of the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(example):\n",
    "    #example grabs the \"text\" field from each example in dataset. \n",
    "    # \"padding\" pads all sequences to the max length, and then truncates any \n",
    "    # sequences longer than the max length.\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "#first two line applies tokenize_function for every example in the dataset and instead of \n",
    "# processing one record at a time, this line of code runs them in batches\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "train_dataset = train_dataset.remove_columns([\"text\", \"__index_level_0__\"])\n",
    "val_dataset = val_dataset.remove_columns([\"text\", \"__index_level_0__\"])\n",
    "#BERT doesn't need raw text during training - it uses token IDs. \n",
    "train_dataset.set_format(\"torch\")\n",
    "val_dataset.set_format(\"torch\")\n",
    "#tokenize and ready for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae454fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a7bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    #evaluate the model at the end of every epoch, 3 in total, save at end\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    #train with 8 samples per batch\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    #run for 3 full passes through the training data, weight decay to reduce\n",
    "    #overfitting. folder to store training logs for tensorboard\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42951475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d728e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159e5039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation/test set NOOOOOOOOO\n",
    "output = trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "\n",
    "# Predict on new data\n",
    "trainer.predict(test_dataset)\n",
    "\n",
    "# Save model manually (optional)\n",
    "trainer.save_model(\"my_saved_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5909e19a",
   "metadata": {},
   "source": [
    "WORD CLOUD VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ec590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Making sure that our dataset has the correct column names\n",
    "dataset = df.copy() #df is main combined dataset of real and fake news\n",
    "dataset = dataset.rename(columns={\"label\": \"target\"})\n",
    "\n",
    "# WordCloud for Real News (target = 1)\n",
    "#Combine all titles where the target is 1 (real news) into one large string\n",
    "consolidated = ' '.join(word for word in dataset['title'][dataset['target'] == 1].astype(str))\n",
    "#Create a WorldClloud object wit specific demensions and settings\n",
    "wordCloud = WordCloud(width=1600, height=800, random_state=21, max_font_size=110, collocations=False)\n",
    "#Figure size for displaying the word cloud\n",
    "plt.figure(figsize=(15, 10))\n",
    "#Generate and display the word cloud image\n",
    "plt.imshow(wordCloud.generate(consolidated), interpolation='bilinear')\n",
    "#Remove axes from the image\n",
    "plt.axis('off')\n",
    "#Add a title to plot\n",
    "plt.title(\"WordCloud for Real News\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# WordCloud for Fake News (target = 0) repeat the same\n",
    "consolidated = ' '.join(word for word in dataset['title'][dataset['target'] == 0].astype(str))\n",
    "wordCloud = WordCloud(width=1600, height=800, random_state=21, max_font_size=110, collocations=False)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(wordCloud.generate(consolidated), interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"WordCloud for Fake News\", fontsize=20)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
