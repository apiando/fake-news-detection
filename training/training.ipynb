{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88252f6e",
   "metadata": {},
   "source": [
    "Install necessary software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb1373",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q transformers datasets accelerate\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102a14ab",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827af034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a226c0",
   "metadata": {},
   "source": [
    "Import data from CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f97fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df = pd.read_csv(\"True.csv\")\n",
    "fake_df = pd.read_csv(\"Fake.csv\")\n",
    "\n",
    "true_df[\"label\"] = 1\n",
    "fake_df[\"label\"] = 0\n",
    "\n",
    "df = pd.concat([true_df, fake_df], axis=0)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df = df[[\"title\", \"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53191cf4",
   "metadata": {},
   "source": [
    "Display sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3151af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.sample(1000) \n",
    "data = data.drop(columns=[\"text\"]) \n",
    "data.sample(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7630cb15",
   "metadata": {},
   "source": [
    "Load and label the training and test data\n",
    "- Load from both real and fake news datasets\n",
    "- Add a label column: 1 for true, 0 for fake\n",
    "- Combine and shuffle the datasets\n",
    "- Extract the article headline and labels as Python lists\n",
    "- Conduct an 80-20 split for training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fcf62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2)\n",
    "train_df = pd.DataFrame({\"text\": train_texts, \"label\": train_labels})\n",
    "val_df = pd.DataFrame({\"text\": val_texts, \"label\": val_labels})\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1382ea35",
   "metadata": {},
   "source": [
    "Tokenization\n",
    "- Load BERT tokenizer that converts raw text into input IDs and attention masks \n",
    "- Add padding and truncates to 512 tokens max (BERT's limit)\n",
    "- Wrap inputs and labels into datatsets that Trainer can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "train_dataset = train_dataset.remove_columns([\"text\", \"__index_level_0__\"])\n",
    "val_dataset = val_dataset.remove_columns([\"text\", \"__index_level_0__\"])\n",
    "train_dataset.set_format(\"torch\")\n",
    "val_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d364cb5",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae454fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6133da5",
   "metadata": {},
   "source": [
    "Define the arguments for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a7bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8, \n",
    "    per_device_eval_batch_size=8, \n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbecbe4",
   "metadata": {},
   "source": [
    "Define function to compute the metrics for evaluating the model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42951475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd379a9",
   "metadata": {},
   "source": [
    "Train the model (requires a Hugging Face API key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d728e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62501715",
   "metadata": {},
   "source": [
    "Evaluate the model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159e5039",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "\n",
    "trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1222073a",
   "metadata": {},
   "source": [
    "Save trained model and tokenizer for implementation in web interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a419c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"my_saved_model\")\n",
    "tokenizer.save_pretrained(\"my_saved_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "django-e9xvJkBR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
